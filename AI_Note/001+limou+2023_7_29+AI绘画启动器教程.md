

# 1.AI绘画从零开始的AI绘画入门教程

所用到的全部软件皆为开源软件：stable diffusion webui。

# 2.AI做不到的

目前的AI无法做到给一张图片就直接会照着画出来无数张这个物体或人物的图片的。

就比如说：有一个立绘，想让AI只根据这一个立绘就完美画出来各种动作角度，抱歉，做不到或者说是技术限制，目前根本就做不好（这有个专业术语叫`one shot`，即“一次尝试”）。想法是美好的，现实是残酷的。目前局限性很大。

# 3.AI做得到的

从二次元到真人，只要是能画出来的都能画。（秋不赞同画真人，本篇教程也完全不会涉及到任何相关内容。）

1. 通过文字描述凭空生成一张图片（文生图功能）

2. 在基础图片上重新绘制或修改一幅图片（图生图功能）

尽管无法绘画出各种角度，但是AI经过一定调教可以做到画风的模拟（训练模型），在拥有足够的素材进行训练以后，就可以学习到一个人物或者画师的画风。通常来说，要拥有较好的效果，人物学习最低需要10张以上。画风学习需要50张以上。

# 4.AI绘画所需配置

在当前启动器下所推荐配置：拥有Nvidia独立显卡、RTX20系以后的显卡。仅生成图片推荐8G显存（4G是最低保障配置）训练推荐大于12G（越大越好）内存推荐16G及以上。硬盘推荐使用固态硬盘，否则你开软件要等个5-10分钟。CPU不做太多要求。

A卡能用，但是性能损耗很大。可以在Linux系统上获得最佳效果。

# 5.下载安装整合包

秋于2023/4/16更新最新的整合包，无需任何替换即可达到最佳速度，打开即用，内置启动器，详情见[视频链接](https://www.bilibili.com/video/BV1iM4y1y7oA/)。

# 6.下载时遇到问题

启动器内拥有 “疑难解答” 功能，可以自动扫描绝大部分问题。同时秋也写了[答疑专栏](https://www.bilibili.com/read/cv20514282?from=articleDetail)，会定期更新一些常见问题.

# 7.入门基础

![png@1256w_630h_!web-article-pic](https://i0.hdslb.com/bfs/article/watermark/58e248f667f8932526774d1835ccf8f3f25d7009.png@1256w_630h_!web-article-pic.webp)

## 7.1.文生图基础使用

由文字描述直接生成图片（待更新Hiresfix讲解）。

### 7.1.1.正面和反面Tag

通用正面 Tag（想要的内容）改善画质用的 Tag：masterpiece, best quality（杰作，最佳品质）。

通用反面 Tag（不想要的内容），保底不出古神用的 Tag：lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry（低分辨率，糟糕的解剖结构，糟糕的手，文本，错误，缺失的手指，多余的数字，更少的数字，裁剪，最差的质量，低质量，普通质量，jpeg压缩伪影，签名，水印，用户名，模糊）。

整合包内一般都会带一个自动补全Tag的插件，如果不知道那些Tag好，可以使用[标签超市](https://tags.novelai.dev/)

> 另外，你可能会看到别人发的Tag里面会有一些符号？比如大小括号等等。这属于进阶用法，这里仅仅简单提及一下。以girl这个 Tag 作为例子。
> 
> (girl)加权重，这里是1.1倍。括号是可以叠加的，如:（(girl))加很多权重。1.1*1.1=1.21倍
> 
> [girl]减权重，一般用的少。减权重也一般就用下面的指定倍数。
> 
> (girl:1.5)指定倍数，这里是1.5倍的权重。还可以(girl:0.9)达到减权重的效果

### 7.1.2.采样迭代步数和采样器

采样步数不需要太大，一般在50以内。通常28是一个不错的值。

采样器没有优劣之分，但是他们速度不同。全看个人喜好。推荐的是图中圈出来的几个，速度效果都不错。

> 这些是一些采样方法的名称。以下是对每个方法的简要说明：
> 
> 1. Euler: 埃尔方法是一种常用的数值积分方法，用于求解常微分方程。
> 
> 2. LMS: 最小均方算法（Least Mean Squares），主要用于自适应滤波和信号处理中。
> 
> 3. Heun: Heun方法是一种改进的欧拉方法，也用于求解常微分方程。
> 
> 4. DPM2: 二阶偏微分方法（Second-Order Partial Differential Method），用于图像处理和计算机视觉中。
> 
> 5. DPM2 a: 与DPM2类似，但经过了改进的版本。
> 
> 6. DPM++ 2S a: DPM++（Double Partial Method）的改进版，用于解决图像处理问题。
> 
> 7. DPM++ 2M: DPM++的另一种改进版本。
> 
> 8. DPM++ SDE: DPM++的随机微分方程版本，用于建模随机过程和噪声。
> 
> 9. DPM fast: DPM++的快速实现版本。
> 
> 10. DPM adaptive: DPM++的自适应方法，根据问题的特性动态地选择合适的计算策略。
> 
> 11. LMS Karras: Karras提出的LMS算法改进版本。
> 
> 12. DPM2 Karras: Karras提出的DPM2算法改进版本。
> 
> 13. DPM2 a Karras: Karras提出的DPM2 a算法改进版本。
> 
> 14. DPM++ 2S a Karras: Karras提出的DPM++ 2S a算法改进版本。
> 
> 15. DPM++ 2M Karras: Karras提出的DPM++ 2M算法改进版本。
> 
> 16. DPM++ SDE Karras: Karras提出的DPM++ SDE算法改进版本。
> 
> 17. DDIM: 延迟差分法（Delayed Difference Method），用于非线性动态系统建模和控制。
> 
> 18. PLMS: 快速最小均方算法（Fast Least Mean Squares），用于自适应滤波和信号处理。
> 
> 19. UniPC: 均匀相位采样（Uniform Phase Sampling），用于图像和信号处理中。
> 
> 这些方法都是在不同领域和问题背景下使用的数值计算或采样方法，具体使用取决于实际需求。
> 
> 这些有能力了再去了解吧……

### 7.1.3.提示词相关代表

![png@1256w_212h_!web-article-pic](https://i0.hdslb.com/bfs/article/df02abbeca054c3d7776c62b35fddd117f85dfea.png@1256w_212h_!web-article-pic.webp)

提示词相关性代表你输入的 Tag 对画面的引导程度有多大，可以理解为 “越小AI越自由发挥”

太大会出现锐化、线条变粗的效果。太小AI就自由发挥了，不看Tag

### 7.1.4.随机种子

随机种子是生成过程中所有随机性的源头，每个种子都是一幅不一样的画。默认的 -1 是代表每次都换一个随机种子。由随机种子，生成了随机的噪声图，再交给AI进行画出来。

## 7.2.图生图基础使用

略

## 7.3.为生成的图片进行放大

AI 基本上无法生成超级大图，想要生成高清图片正确的做法是生成2k以内分辨率的图片再使用放大功能（也叫超分辨率）进行放大图片。

## 7.4.查询图片参数

AI生成图片会自动保存全部参数到原图中，可以在WebUI的 “图片信息” 一栏内通过解析原图查看到。也可以使用秋写的这个[工具](https://spell.novelai.dev/)

![eadc2efb-6ac0-4674-b164-e67680ca132c](file:///C:/Users/Limou_p350ml9/Pictures/Typedown/eadc2efb-6ac0-4674-b164-e67680ca132c.png)

![935f6577-8594-4e81-97e5-28f0f18c1d97](file:///C:/Users/Limou_p350ml9/Pictures/Typedown/935f6577-8594-4e81-97e5-28f0f18c1d97.png)

非AI生成图片或经过压缩的图片可以通过Deepdanbooru、Tagger来尝试反推tag。

![png@1256w_612h_!web-article-pic](https://i0.hdslb.com/bfs/article/ebf0c083097b726f5bc986e135794bab626c4de0.png@1256w_612h_!web-article-pic.webp)

Deepdanbooru 默认已经自带了，可以在图生图页面找到。

Tagger是一个插件，在新版的整合包内也帮你装好了，可以在顶栏找到。如果没有的话需要自行安装，安装教程参考下面的插件管理部分，[视频较早，仅供参考](https://www.bilibili.com/video/BV17e4y1m7GZ/)。

![png@1256w_638h_!web-article-pic](https://i0.hdslb.com/bfs/article/487b0328473d86c8c3ddd2b5055dd586d58abd60.png@1256w_638h_!web-article-pic.webp)

## 7.5.使用X/Y图表

在生成图片时候，可以使用x/y图表快速生成不同参数的图片进行对比。

一个图表示例，常用做对比图
（待更新专栏，可以先看看下面这个网站）

https://guide.novelai.dev/guide/configuration/param-advanced#x-y-z-图表

## 7.6.使用图库浏览器

使用图库浏览器插件管理生成的图片。

## 7.7安装/管理/更新插件

通过 WebUI 自带的插件管理系统安装插件，并且及时更新。推荐使用启动器进行更新插件，更为快捷。

# 8.进阶使用

## 8.1.使用高级提示词语法

提示词权重、分步渲染相关内容

https://guide.novelai.dev/guide/prompt-engineering/txt2img#提示词语法

## 8.2.更换模型来达到不同的画风/认识不同人物、物体

参考以下文章。

目前可以见到的模型有：大模型、Embedding模型、Hypernet模型、LoRA模型

常用：大模型、LoRA模型。

模型推荐



## 8.3.用模型合并来混合风格

视频内有一部分提到这个。可以参考

（待更新：mbw等新型合并）

## 8.4.使用ControlNet精细控制画面

Controlnet 1.1 版本更新



# 9.带师级别使用

## 9.1.自己进行训练模型

Embedding (Textual inversion)

Hypernetwork

不更新了

LoRA

在今年的5月份，我制作了LoRA训练的界面+一键包。推荐使用这个新视频下载的一键包，打开就可以训练。训练教程仍然参考下方的旧教程，但是不再需要跟着安装了，参数也是用界面调整的



Dreambooth / Native Train （finetune）



## 9.2.训练模型理论基础（涉及部分专业知识）



## 9.3.更加深入理解原理



# 10.前沿探索

都前沿了还需要我引路？自己看去吧。学无止境我也自己在学习。

简单说一下：arXiv翻论文，Github翻最新代码实现。关注关注CVPR等

关注关注沐神（搜李沐）

关注我的最新动态，随时会发点新玩意



# 11.相关推荐

## 11.1.AI绘画相关

@大江户战士 

@只剩一瓶辣椒酱 

@独立研究员-星空 

## 11.2.LoRA训练

@青龙圣者 

@WSH032 

[NovelAI.dev](https://novelai.dev/)

[详细教程/使用文档（部分内容过时）](https://guide.novelai.dev/)

[Huggingface模型站](https://huggingface.co/)

## 11.3.理论AI知识相关

@跟李沐学AI 秋说是唯一神
